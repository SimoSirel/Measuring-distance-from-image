{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ludvigl/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "#Kui kasutate vanemat (v1) Tensorflow versiooni, \n",
    "#siis äkki peab siin midagi muutma, kui ei tööta\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_v2_behavior() \n",
    "\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "import time\n",
    "from deep_sort import nn_matching\n",
    "from deep_sort.detection import Detection\n",
    "from deep_sort.tracker import Tracker\n",
    "from deep_sort import generate_detections as gdet\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_images(video, size = None):\n",
    "    # Params: video as VideoCapture\n",
    "    # Yields resized images\n",
    "    # video = cv2.VideoCapture(video_filename)\n",
    "    success, image = video.read()\n",
    "    \n",
    "    while success:\n",
    "        # resize image\n",
    "        if size:\n",
    "            image = cv2.resize(image, size, interpolation = cv2.INTER_AREA)\n",
    "        yield image\n",
    "        success, image = video.read()\n",
    "        \n",
    "    video.release();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coord(bbox, width, height):\n",
    "    \"\"\"Return boxes coordinates\"\"\"\n",
    "    \n",
    "    xmin = bbox[1] * width\n",
    "    ymin = bbox[0] * height\n",
    "    xmax = bbox[3] * width\n",
    "    ymax = bbox[2] * height\n",
    "\n",
    "    return [xmin, ymin, xmax - xmin, ymax - ymin]\n",
    "    \n",
    "def calculate_centr(coord):\n",
    "    \"\"\"Calculate centroid for each box\"\"\"\n",
    "    return (coord[0]+(coord[2]/2), coord[1]+(coord[3]/2))\n",
    "  \n",
    "\n",
    "def calculate_centr_distances(centroid_1, centroid_2):\n",
    "    \n",
    "    \"\"\"Calculate the distance between 2 centroids\"\"\"\n",
    "    return math.sqrt((centroid_2[0]-centroid_1[0])**2 + (centroid_2[1]-centroid_1[1])**2)\n",
    "    \n",
    "def calculate_perm(centroids):\n",
    "    \"\"\"Return all combinations of centroids\"\"\"\n",
    "    permutations = []\n",
    "    for current_permutation in itertools.permutations(centroids, 2):\n",
    "        if current_permutation[::-1] not in permutations:\n",
    "            permutations.append(current_permutation)\n",
    "    return permutations\n",
    "  \n",
    "def calc_midpoint(p1, p2):\n",
    "    \"\"\"Midpoint between 2 points\"\"\"\n",
    "    return ((p1[0] + p2[0])/2, (p1[1] + p2[1])/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - fill this with something\n",
    "\n",
    "def calculate_distances(permutations, rects, width, height):\n",
    "    # Permutations - list of tuples [((x1, y1),(x2, y2))]\n",
    "    # Rects - Lists of  [x, y, width, height]\n",
    "    # Size - (width, height)\n",
    "    distances = []\n",
    "    \n",
    "    for perm in permutations:\n",
    "        #first centroid  coordinate\n",
    "        x1 = perm[0][0]\n",
    "        y1 = perm[0][1]\n",
    "        #second centroid coorinate\n",
    "        x2 = perm[1][0]\n",
    "        y2 = perm[1][1]\n",
    "        \n",
    "        average_px_meter = (width-540) / 10 #lambist proovitud arv\n",
    "        \n",
    "        dist = calculate_centr_distances(perm[0], perm[1])\n",
    "        #print(dist)\n",
    "        dist_m = dist/ average_px_meter\n",
    "        #print(\"M meters: \", str(dist_m))\n",
    "\n",
    "        distances.append(dist_m)\n",
    "    # Returns distances - list of distances as numbers\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rects(image, coordinates, color = (0, 0, 255), thickness = 3):\n",
    "    # Draws rectangles onto the image\n",
    "    # input list of Lists of  [x, y, width, height] \n",
    "    # color is tuple in BGR\n",
    "    # thickness is thickness of line in pixels\n",
    "    \n",
    "    for i in range(len(coordinates)):\n",
    "        coord = coordinates[i]\n",
    "\n",
    "        x1 = int(coord[0])\n",
    "        y1 = int(coord[1])\n",
    "        x2 = x1 + int(coord[2])\n",
    "        y2 = y1 + int(coord[3])\n",
    "\n",
    "        #image = cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def draw_lines(image, permutations, distances, color = (0, 255, 255), thickness = 1):\n",
    "    # Given pairs of permutations\n",
    "    # Draws lines between Centroids \n",
    "    \n",
    "    for i, perm in enumerate(permutations):\n",
    "        point1, point2 = perm[0], perm[1]\n",
    "        point1 = tuple(map(int, point1))\n",
    "        point2 = tuple(map(int, point2))\n",
    "        x1 = point1[0]\n",
    "        y1 = point1[1]\n",
    "        x2 = point2[0]\n",
    "        y2 = point2[1]\n",
    "        #image = cv2.line(image, point1, point2, color, thickness)\n",
    "        mid = tuple(map(int, calc_midpoint(point1, point2)))\n",
    " \n",
    "        #if round(distances[i], 1) < 2.0:\n",
    "         #   cv2.putText(image, str(round(distances[i], 1)) +'m', mid, font, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        #else:\n",
    "         #   cv2.putText(image, str(round(distances[i], 1)) +'m', mid, font, 2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input  -  data/test_video_4K_25fps.mp4\n",
      "Output -  data/output.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ab468b30e1af>:30: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  with tqdm(total=total_frames) as pbar:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7378abbe7b449393db6f834037e9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=915.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output saved\n"
     ]
    }
   ],
   "source": [
    "input_video_filename = 'data/test_video_4K_25fps.mp4'\n",
    "output_video_filename = 'data/output.avi'\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "input_video_filepath = input_video_filename\n",
    "output_video_filepath = output_video_filename\n",
    "print(\"Input  - \",input_video_filepath)\n",
    "print(\"Output - \",output_video_filepath)\n",
    "\n",
    "input_video = cv2.VideoCapture(input_video_filepath)\n",
    "fps = input_video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "Width  = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))  # float\n",
    "Height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT)) # float\n",
    "total_frames = int(input_video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter(output_video_filepath, fourcc, fps, (Width, Height))\n",
    "\n",
    "\n",
    "classes = None\n",
    "with open('coco.names.txt', 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# read pre-trained model and config file\n",
    "net = cv2.dnn.readNet('./model_data/yolov3.weights', 'yolov3.cfg') \n",
    "\n",
    "\n",
    "try: \n",
    "    with tqdm(total=total_frames) as pbar:\n",
    "        for image in video_to_images(input_video):\n",
    "        \n",
    "            net.setInput(cv2.dnn.blobFromImage(image, 0.00392, (416,416), (0,0,0), True, crop=False))\n",
    "\n",
    "            # run inference through the network\n",
    "            # and gather predictions from output layers\n",
    "\n",
    "            layer_names = net.getLayerNames()\n",
    "            output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "            outs = net.forward(output_layers)\n",
    "\n",
    "\n",
    "            class_ids = []\n",
    "            confidences = []\n",
    "            boxes = []\n",
    "\n",
    "            #create bounding box \n",
    "            for out in outs:\n",
    "                for detection in out:\n",
    "                    \n",
    "                    scores = detection[5:]\n",
    "                    class_id = np.argmax(scores)\n",
    "                    if class_id == 0:\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.1:\n",
    "                            center_x = int(detection[0] * Width)\n",
    "                            center_y = int(detection[1] * Height)\n",
    "                            w = int(detection[2] * Width)\n",
    "                            h = int(detection[3] * Height)\n",
    "                            x = center_x - w / 2\n",
    "                            y = center_y - h / 2\n",
    "                            class_ids.append(class_id)\n",
    "                            confidences.append(float(confidence))\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            \n",
    "\n",
    "            indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.1)\n",
    "\n",
    "            # Tuples of (x, y) coords\n",
    "            centroids = []\n",
    "            # Lists of  [x, y, width, height]\n",
    "            coordinates = []\n",
    "            for i in indices:\n",
    "                i = i[0]\n",
    "                box = boxes[i]\n",
    "                centr = calculate_centr(box)\n",
    "                centroids.append(centr)\n",
    "                coordinates.append(box)\n",
    "                if class_ids[i]==0:\n",
    "                    label = str(classes[class_id]) \n",
    "                    cv2.rectangle(image, (round(box[0]),round(box[1])), (round(box[0]+box[2]),round(box[1]+box[3])), (0, 0, 0), 2)\n",
    "                    cv2.putText(image, label, (round(box[0])-10,round(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "           \n",
    "        \n",
    "            # Calculate all possible connections between centroids\n",
    "            permutations = calculate_perm(centroids)\n",
    "            distances = calculate_distances(permutations, coordinates, Width, Height)\n",
    "        \n",
    "            #draw_rects(image, coordinates)\n",
    "            draw_lines(image, permutations, distances)\n",
    "            # Write to output video file\n",
    "            output_video.write(image)\n",
    "            pbar.update(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Process stopped\")\n",
    "finally:\n",
    "    print(\"Output saved\")\n",
    "    output_video.release() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
